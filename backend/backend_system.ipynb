{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load('svm_model.pkl')\n",
    "loaded_scaler = load('standard_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"When Obama was sworn into office, he DID NOT use the Holy Bible, but instead the Kuran (Their equivalency to our Bible, but very different beliefs).\" #input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC_analysis_result = None\n",
    "\n",
    "cmd_to_execute = [\n",
    "    \"LIWC-22-cli\",\n",
    "    \"--mode\", \"wc\",\n",
    "    \"--input\", \"console\",\n",
    "    \"--console-text\", sentence,\n",
    "    \"--output\", \"console\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    results = subprocess.check_output(cmd_to_execute, stderr=subprocess.DEVNULL).decode().strip().splitlines()\n",
    "    LIWC_analysis_result = results[7]\n",
    "except Exception as e:\n",
    "    print(f\"Error processing sentence: {sentence}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\"Segment\": 1,\"WC\": 26,\"Analytic\": 14.06,\"Clout\": 2.37,\"Authentic\": 98.89,\"Tone\": 79.29,\"WPS\": 26,\"BigWords\": 15.38,\"Dic\": 88.46,\"Linguistic\": 73.08,\"function\": 57.69,\"pronoun\": 11.54,\"ppron\": 11.54,\"i\": 0,\"we\": 3.85,\"you\": 0,\"shehe\": 3.85,\"they\": 3.85,\"ipron\": 0,\"det\": 15.38,\"article\": 7.69,\"number\": 0,\"prep\": 7.69,\"auxverb\": 7.69,\"adverb\": 11.54,\"conj\": 11.54,\"negate\": 3.85,\"verb\": 11.54,\"adj\": 7.69,\"quantity\": 3.85,\"Drives\": 3.85,\"affiliation\": 3.85,\"achieve\": 0,\"power\": 0,\"Cognition\": 30.77,\"allnone\": 0,\"cogproc\": 30.77,\"insight\": 3.85,\"cause\": 3.85,\"discrep\": 0,\"tentat\": 0,\"certitude\": 0,\"differ\": 23.08,\"memory\": 0,\"Affect\": 3.85,\"tone_pos\": 3.85,\"tone_neg\": 0,\"emotion\": 0,\"emo_pos\": 0,\"emo_neg\": 0,\"emo_anx\": 0,\"emo_anger\": 0,\"emo_sad\": 0,\"swear\": 0,\"Social\": 11.54,\"socbehav\": 0,\"prosocial\": 0,\"polite\": 0,\"conflict\": 0,\"moral\": 0,\"comm\": 0,\"socrefs\": 11.54,\"family\": 0,\"friend\": 0,\"female\": 0,\"male\": 3.85,\"Culture\": 0,\"politic\": 0,\"ethnicity\": 0,\"tech\": 0,\"Lifestyle\": 15.38,\"leisure\": 0,\"home\": 0,\"work\": 3.85,\"money\": 0,\"relig\": 11.54,\"Physical\": 0,\"health\": 0,\"illness\": 0,\"wellness\": 0,\"mental\": 0,\"substances\": 0,\"sexual\": 0,\"food\": 0,\"death\": 0,\"need\": 0,\"want\": 0,\"acquire\": 0,\"lack\": 0,\"fulfill\": 0,\"fatigue\": 0,\"reward\": 0,\"risk\": 0,\"curiosity\": 0,\"allure\": 0,\"Perception\": 3.85,\"attention\": 0,\"motion\": 0,\"space\": 3.85,\"visual\": 0,\"auditory\": 0,\"feeling\": 0,\"time\": 3.85,\"focuspast\": 7.69,\"focuspresent\": 0,\"focusfuture\": 0,\"Conversation\": 0,\"netspeak\": 0,\"assent\": 0,\"nonflu\": 0,\"filler\": 0,\"AllPunc\": 23.08,\"Period\": 3.85,\"Comma\": 11.54,\"QMark\": 0,\"Exclam\": 0,\"Apostro\": 0,\"OtherP\": 7.69,\"Emoji\": 0}\n"
     ]
    }
   ],
   "source": [
    "print(type(LIWC_analysis_result))\n",
    "print(LIWC_analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIWC_analysis_result = json.loads(LIWC_analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Segment  WC  Analytic  Clout  Authentic   Tone  WPS  BigWords    Dic   \n",
      "0        1  26     14.06   2.37      98.89  79.29   26     15.38  88.46  \\\n",
      "\n",
      "   Linguistic  ...  nonflu  filler  AllPunc  Period  Comma  QMark  Exclam   \n",
      "0       73.08  ...       0       0    23.08    3.85  11.54      0       0  \\\n",
      "\n",
      "   Apostro  OtherP  Emoji  \n",
      "0        0    7.69      0  \n",
      "\n",
      "[1 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = [key for key, _ in LIWC_analysis_result.items()]\n",
    "values = [value for _, value in LIWC_analysis_result.items()]\n",
    "pd_dataframe = pd.DataFrame({column : [value] for column, value in zip(columns, values)})\n",
    "print(pd_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = []\n",
    "\n",
    "with open('columns_to_scale', 'r') as f:\n",
    "    columns_to_scale = [line.rstrip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Emoji', 'Exclam', 'cause', 'WPS', 'cogproc', 'i', 'attention', 'reward', 'conflict', 'affiliation', 'pronoun', 'female', 'Comma', 'space', 'Authentic', 'Lifestyle', 'death', 'verb', 'emo_neg', 'swear', 'want', 'need', 'allure', 'focusfuture', 'allnone', 'lack', 'conj', 'focuspast', 'filler', 'function', 'power', 'quantity', 'risk', 'Period', 'illness', 'OtherP', 'Affect', 'Culture', 'tone_neg', 'QMark', 'BigWords', 'tentat', 'home', 'curiosity', 'Drives', 'substances', 'negate', 'differ', 'Cognition', 'socbehav', 'prosocial', 'ethnicity', 'feeling', 'auxverb', 'you', 'Analytic', 'family', 'Conversation', 'Dic', 'certitude', 'ppron', 'netspeak', 'det', 'comm', 'health', 'leisure', 'memory', 'insight', 'emo_sad', 'WC', 'discrep', 'Social', 'Segment', 'work', 'shehe', 'moral', 'acquire', 'fulfill', 'food', 'ipron', 'they', 'polite', 'socrefs', 'adj', 'Apostro', 'male', 'adverb', 'Linguistic', 'number', 'emo_pos', 'we', 'emo_anx', 'motion', 'focuspresent', 'Clout', 'wellness', 'Perception', 'tone_pos', 'achieve', 'politic', 'AllPunc', 'relig', 'Tone', 'auditory', 'mental', 'Physical', 'time', 'assent', 'nonflu', 'tech', 'sexual', 'friend', 'article', 'visual', 'emotion', 'prep', 'money', 'fatigue', 'emo_anger']\n"
     ]
    }
   ],
   "source": [
    "print(columns_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00, -8.35604942e-18,  3.85000000e+00,\n",
       "         2.60000000e+01,  3.07700000e+01,  1.67120988e-17,\n",
       "        -1.14895680e-17, -1.51453396e-17,  7.65971197e-18,\n",
       "         3.85000000e+00,  1.15400000e+01,  3.89948973e-17,\n",
       "         1.15400000e+01,  3.85000000e+00,  9.88900000e+01,\n",
       "         1.53800000e+01,  3.48168726e-18,  1.15400000e+01,\n",
       "        -2.92461730e-17,  2.08901236e-18,  1.21859054e-17,\n",
       "        -4.17802471e-18,  2.08901236e-18, -8.35604942e-18,\n",
       "        -8.35604942e-18, -2.78534981e-18,  1.15400000e+01,\n",
       "         7.69000000e+00,  0.00000000e+00,  5.76900000e+01,\n",
       "         1.39267490e-17,  3.85000000e+00,  1.67120988e-17,\n",
       "         3.85000000e+00,  0.00000000e+00,  7.69000000e+00,\n",
       "         3.85000000e+00, -3.48168726e-17,  3.89948973e-17,\n",
       "         2.43718108e-18,  1.53800000e+01,  6.78929015e-17,\n",
       "        -2.78534981e-17,  5.50106587e-17,  3.85000000e+00,\n",
       "        -3.20315228e-17,  3.85000000e+00,  2.30800000e+01,\n",
       "         3.07700000e+01,  2.78534981e-18,  2.22827985e-17,\n",
       "        -7.86861320e-17,  3.69058849e-17,  7.69000000e+00,\n",
       "         8.35604942e-18,  1.40600000e+01, -2.68089919e-17,\n",
       "         6.96337452e-19,  8.84600000e+01, -2.43718108e-17,\n",
       "         1.15400000e+01,  3.02906792e-17,  1.53800000e+01,\n",
       "        -3.34241977e-17,  1.39267490e-17, -5.70996710e-17,\n",
       "        -8.35604942e-18,  3.85000000e+00,  5.91886834e-18,\n",
       "         2.60000000e+01,  1.53194239e-17,  1.15400000e+01,\n",
       "         1.00000000e+00,  3.85000000e+00,  3.85000000e+00,\n",
       "        -4.17802471e-18,  4.21284158e-17, -2.08901236e-17,\n",
       "         2.92461730e-17,  1.18377367e-17,  3.85000000e+00,\n",
       "         1.56675927e-17,  1.15400000e+01,  7.69000000e+00,\n",
       "        -1.53194239e-17,  3.85000000e+00,  1.15400000e+01,\n",
       "         7.30800000e+01, -1.94974486e-17,  1.07932305e-17,\n",
       "         3.85000000e+00,  6.26703707e-18,  1.74084363e-18,\n",
       "        -2.61126544e-18,  2.37000000e+00,  1.03580196e-17,\n",
       "         3.85000000e+00,  3.85000000e+00, -2.78534981e-17,\n",
       "         3.76022224e-17,  2.30800000e+01,  1.15400000e+01,\n",
       "         7.92900000e+01,  6.96337452e-18, -4.17802471e-18,\n",
       "         2.15864610e-17,  3.85000000e+00,  2.00197017e-18,\n",
       "        -5.91886834e-18,  3.76022224e-17, -1.18377367e-17,\n",
       "         4.31729220e-17,  7.69000000e+00, -8.35604942e-18,\n",
       "         2.01937861e-17,  7.69000000e+00, -4.45655969e-17,\n",
       "        -2.08901236e-18,  1.42749178e-17]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the data\n",
    "loaded_scaler.transform(pd_dataframe[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_predict = []\n",
    "\n",
    "with open('columns_to_scale', 'r') as f:\n",
    "    columns_to_predict = [line.rstrip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict(pd_dataframe[columns_to_predict])\n",
    "probability = loaded_model.predict_proba(pd_dataframe[columns_to_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade cohere\n",
    "import cohere\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"Barack Obama bible kuran\"\n",
      "Explanation: \"Barack Obama did not use the Holy Bible in his inauguration but instead opted for the Kuran, which is the Islamic religious text\"\n",
      "Barack Obama bible kuran\n"
     ]
    }
   ],
   "source": [
    "co = cohere.Client('AMvBl8oPDG1sJrA5Zeqqs9qMR6pIdSWVYLrDif1M')\n",
    "\n",
    "sentence = \"When Obama was sworn into office, he DID NOT use the Holy Bible, but instead the Kuran (Their equivalency to our Bible, but very different beliefs).\"\n",
    "prompt = f\"\"\"\n",
    "[INST] <<SYS>>\n",
    "I would like to check if below statement is true on Google fact check explorer. \n",
    "I believe that it is very hard to find the results by simply searching the whole sentence, suggest appropriate very short query by extracting keywords. \n",
    "\n",
    "Format\n",
    "Query: \"Your suggestion here\"\n",
    "Explanation: \"Your explanation here\"\n",
    "<</SYS>>\n",
    "Statements: {sentence} [/INST]\n",
    "Setting seed to 1\n",
    "\"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "\tprompt, \n",
    "\tmodel=\"command\", \n",
    "\ttemperature=0.1\n",
    ")\n",
    "answer = response.text\n",
    "text_output = \"\".join(answer)\n",
    "match = re.search(r'Query: \"(.*?)\"', text_output)\n",
    "query = match.group(1) if match else None\n",
    "\n",
    "print(answer)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'claims': [{'text': '“For those who don’t believe Obama is a Muslim, the red book is the Quran.”', 'claimant': 'Viral meme', 'claimDate': '2018-12-05T00:00:00Z', 'claimReview': [{'publisher': {'name': 'FactCheck.org', 'site': 'factcheck.org'}, 'url': 'https://www.factcheck.org/2018/12/meme-confuses-lincolns-bible-with-a-quran/', 'title': \"Meme Confuses Lincoln's Bible With A Quran\", 'reviewDate': '2018-12-10T15:24:44Z', 'textualRating': 'False', 'languageCode': 'en'}]}]}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the API endpoint and parameters\n",
    "endpoint = \"https://factchecktools.googleapis.com/v1alpha1/claims:search\"\n",
    "results_list = []\n",
    "\n",
    "params = {\n",
    "    'query': query,\n",
    "    'languageCode': 'en-US',\n",
    "    'pageSize': 10,\n",
    "    'key': 'AIzaSyCiPY5hrNpKHCZ1d-htnrhvQ_EjOFbBi0E'\n",
    "}\n",
    "\n",
    "# Make the GET request\n",
    "response = requests.get(endpoint, params=params)\n",
    "\n",
    "# Check for a successful response\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    results_list.append(data)\n",
    "    print(results_list)\n",
    "else:\n",
    "    print(f\"Failed to retrieve data: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "[INST] <<SYS>>\n",
    "I would like to use following informations to detect fake news. Using below results, explain why or why\n",
    "not below sentence is likely fake news.\n",
    "1. Support vector machine model prediction result based on LIWC analysis of statement\n",
    "2. Related source search results from Google fact check explorer database. \n",
    "<</SYS>>\n",
    "Statement = {sentence}\n",
    "Support vector machine model prediction: {probability[0][0]:.4f} probability of fake news.\n",
    "Google fact check explorer result: {str(results_list)} [/INST]\n",
    "Setting seed to 1\n",
    "\"\"\"\n",
    "\n",
    "response = co.chat(\n",
    "\tprompt, \n",
    "\tmodel=\"command\", \n",
    "\ttemperature=0.1\n",
    ")\n",
    "answer = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Support Vector Machine (SVM) model predicts a 0.0000 probability of the statement being fake news. However, the Google Fact Check Explorer result returns a false rating from factcheck.org, which states that the claim is false. This suggests that the statement is indeed fake news, as it is contradicted by a reliable source. Therefore, the statement is likely false news.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
